\documentclass[english,11pt,a4paper]{article}

\input{macros}

\newcommand\inner[2]{\langle #1, #2 \rangle}

\usepackage{a4wide}
\usepackage{tikz}

\title{Ideas for Splitting Deep Networks}
\author{}
\usepackage{amsmath,epsfig,amssymb,amsbsy}

\begin{document}
\maketitle

\section{Objective function}

The aim is to solve a supervised regression or classification problem involving a highly nested objective function. A mapping $f(x)$ from the inputs $x$ to the corresponding outputs $y$ based on $N$ training samples $(x_n, y_n)$ should be learned. The loss function can be formulated as

\begin{equation}
E(W) = \frac{1}{2} \sum_{i=1}^{N} L(y_i, f(W;x_i))
\end{equation}

with some appropriate error measure $L(y,x)$. This error measure can for example be the squared l2-loss $L(y,x) = \frac{1}{2} \| y - x \|^2_2$. The function $f(W;x) = W_{K+1}h(W_Kh(\dots h(W_1x))$ is a nested K-layer mapping as it is usual in neural networks where $W$ are the weight matrices $W_1,\dots,W_{K+1}$ which do not need to have the same size. The nonlinear activation function $h(x)$ is applied element-wise and can also be non-differential. Examples are the sigmoid function $h(x) = 1/(1 + e^{-x})$ or the ReLU $h(x) = \mathrm{max}(0, x)$.

\section{Solution concept}

In the following, for simplicity only one sample point $(x,y)$ is used. Additionally, without loss of generality we consider a 2-layer neural network mapping $f(W;x) = W_3h(W_2h(W_1x))$ with a linear mapping to the output variables. The unconstrained optimization problem can then be written as

\begin{equation}
	\begin{aligned}
		& \underset{\{W_i\}}{\text{minimize}}
		& & L(y,W_3h(W_2h(W_1x)).
	\end{aligned}
\end{equation}

To split the nested objective function we decouple the weights and activation functions
by introducing additional variables and adding the appropriate constraints. This reformulated problem is equal to the original problem and can be written as

\begin{equation}
	\begin{aligned}
		& \underset{\{W_i,a_i,z\}}{\text{minimize}}
		&& L(y,z). \\
		& \text{subject to}
		&&  a_1 = h(W_1x), \\
		&&& a_2 = h(W_2a_1), \\
		&&& z = W_3a_2
	\end{aligned}
\end{equation}

with the new variables $a_1, a_2, z$. The augmented Lagrangian of this equally constrained problem is

\begin{equation}
	\begin{aligned}
		\mathcal{L}(y,z,a,\lambda) = L(y,z) + 
		& \inner{\lambda_1}{h(W_1x)-a_1} + \rho/2 \| h(W_1x)-a_1 \|^2 + \\
		& \inner{\lambda_2}{h(W_2a_1)-a_2} + \rho/2 \| h(W_2a_1)-a_2 \|^2 + \\
		& \inner{\lambda_3}{W_3a_2-z} + \rho/2 \| W_3a_2-z \|^2.
	\end{aligned}
\end{equation}

with $a = (a_1,a_2)^T$, $\lambda = (\lambda_1, \lambda_2, \lambda_3)^T$ and $\rho \in \R$. For minimizing the objective we update the weights and constraint variables of subproblems in an alternating fashion using gradient descent. In each update step we only consider the variables of one constraint and fix all other terms of the augmented Lagrangian. This results in one subproblem $\mathcal{H}_i$ for each constraint.

\begin{equation}
	\begin{aligned}
		\mathcal{H}_1(W_1,a_2,\lambda_1) &= \inner{\lambda_1}{h(W_1x)-a_1} + \rho/2 \| h(W_1x)-a_1 \|^2 \\
		\mathcal{H}_2(W_2,a_1,a_2,\lambda_2) &= \inner{\lambda_2}{h(W_2a_1)-a_2} + \rho/2 \| h(W_2a_1)-a_2 \|^2 \\
		\mathcal{H}_3(W_3,a_2,z,\lambda_3) &= \inner{\lambda_2}{W_3a_2-z} + \rho/2 \| W_3a_2-z \|^2 + L(y,z)
	\end{aligned}
\end{equation}

We need to take special care of the first subproblem (constraint for the first layer) involving the input $x$ and the last subproblem (constraint for the last linear layer) involving the predicted variable $z$. For all others we consider the update scheme (here for $\mathcal{H}_2$)

\begin{equation}
	\begin{aligned}
		W_2^{t+1} &= W_2^t - \rho \nabla_{W_2}(\mathcal{H}_2(W_2^t,a_1^t,a_2^t,\lambda_2^t)) \\
		a_1^{t+1} &= a_1^t - \rho \nabla_{a_1}(\mathcal{H}_2(W_2^t,a_1^t,a_2^t,\lambda_2^t)) \\
		a_2^{t+1} &= a_2^t - \rho \nabla_{a_2}(\mathcal{H}_2(W_2^{t+1},a_1^{t+1},a_2^t,\lambda_2^t)) \\
		\lambda_2^{t+1} &= \lambda_2^{t} + \rho (h(W_2^{t+1}a_1^{t+1})-a_2^{t+1})
	\end{aligned}
\end{equation}

which are gradient descent steps for the primal variables and gradient ascent steps for the dual variable $\lambda$. For $\mathcal{H}_1$ only $W_1$, $a_2$ and $\lambda_1$ need to be updated since $x$ is a constant. For the last subproblem $\mathcal{H}_{K+1}$ we need to add $\nabla_zL(y,z)$ to the gradient with respect to $z$.

\todo{Which order? Stepsizes?}

\section{Appendix}

\subsection{Gradients}

For the update steps we need the gradient of the terms $f(\cdot) = \inner{\lambda}{h(Wx)-a}$ and $g(\cdot) = (1/2) \| h(Wx) - a \|^2$ with respect to $W \in \R^{m \times n}$, $x \in \R^n$, $a \in \R^m$ and $\lambda \in \R^m$. The function $h$ is applied element-wise.

\todo{Need to check the gradients.}

%\begin{equation}
%	\begin{aligned}
%		\partial_{W_i} f(W,x,a,\lambda) &= \lambda_i h'(W_ix)x \\
%		\partial_{W_i} g(W,x,a) &= (h(W_ix) - a) h'(W_ix)x \\
%		\partial_{a} f(W,x,a,\lambda) &= -\lambda \\
%		\partial_{a} g(W,x,a) &= -h(Wx) + a \\
%		\partial_{x} f(W,x,a,\lambda) &= \sum_{i=1}^{m} \lambda_i h'(W_ix)W_i \\
%		\partial_{x} g(W,x,a) &= (h(Wx)-a) W^Th'(Wx)
%	\end{aligned}
%\end{equation}

\section{Additional notes}

\begin{itemize}
	\item Could add regularizer for the weights.
\end{itemize}

{\small
  \bibliographystyle{ieee}
  \bibliography{references}
}

\end{document}

